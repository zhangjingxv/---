æ¨¡å‹ä¸‹è½½é“¾æ¥https://wxkk6cr9s4x.feishu.cn/drive/folder/OPf4fqS2xlN7HddB4ZxclydQn8f
ä¹¦ç”Ÿ-é‡‘èå¤§æ¨¡å‹

finance-chat
license evaluation

ğŸ¤—HuggingFace | OpenXLab_Model | ModelScope

OpenXLab_App | ğŸ†•Update News | ğŸ¤”Reporting Issues ä¸¨ bilibili

English | ç®€ä½“ä¸­æ–‡

ğŸ“ç›®å½•
ğŸ“– ç®€ä»‹
ğŸš€ News
ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•
å¿«é€Ÿå¼€å§‹
é‡æ–°è®­ç»ƒ
ç¯å¢ƒæ­å»º
XTunerå¾®è°ƒ
OpenXLabåº”ç”¨éƒ¨ç½²
LMDeployé‡åŒ–
OpenCompassè¯„æµ‹
LMDeploy & OpenCompassé‡åŒ–ä»¥åŠé‡åŒ–è¯„æµ‹
ğŸ’• è‡´è°¢
å¼€æºè®¸å¯è¯
ğŸ“– ç®€ä»‹
AM (Advanced Mathematics) chat æ˜¯ä¸€ä¸ªé›†æˆäº†é‡‘èçŸ¥è¯†åŠå…¶è§£ç­”çš„å¤§è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹ä½¿ç”¨ Finance è§£æèåˆçš„æ•°æ®é›†ï¼ŒåŸºäº InternLM2-Finance-7B æ¨¡å‹ï¼Œé€šè¿‡ xtuner å¾®è°ƒï¼Œä¸“é—¨è®¾è®¡ç”¨äºè§£ç­”é‡‘èé—®é¢˜ã€‚

å¦‚æœä½ è§‰å¾—è¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿ â­ Starï¼Œè®©æ›´å¤šçš„äººå‘ç°å®ƒï¼

ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•
å¿«é€Ÿå¼€å§‹
ä¸‹è½½æ¨¡å‹
ä» ModelScope
ä» OpenXLab
æœ¬åœ°éƒ¨ç½²
git clone https://github.com/zhangjingxv/shusheng.git
python start.py
Dockeréƒ¨ç½²
docker run -t -i --rm --gpus all -p 8501:8501 guidonsdocker/amchat:latest bash start.sh
é‡æ–°è®­ç»ƒ
ç¯å¢ƒæ­å»º
clone æœ¬é¡¹ç›®
git clone https://github.com/zhangjingxv/shusheng.git
cd AMchat
åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda env create -f environment.yml
conda activate AMchat
pip install -r requirements-raw.txt
XTunerå¾®è°ƒ
å‡†å¤‡é…ç½®æ–‡ä»¶

åˆ—å‡ºæ‰€æœ‰å†…ç½®é…ç½®
xtuner list-cfg

mkdir -p /root/finance/data
mkdir /root/finance/config && cd /root/finance/config

xtuner copy-cfg internlm2_chat_7b_qlora_oasst1_e3 .
æ¨¡å‹ä¸‹è½½
mkdir -p /root/finance/model
download.py

import torch
from modelscope import snapshot_download, AutoModel, AutoTokenizer
import os
model_dir = snapshot_download('Shanghai_AI_Laboratory/internlm2-finance-7b', cache_dir='/root/finance/model')
ä¿®æ”¹é…ç½®æ–‡ä»¶
cd /root/finance/config
vim internlm_chat_7b_qlora_oasst1_e3_copy.py

ä¿®æ”¹æ¨¡å‹ä¸ºæœ¬åœ°è·¯å¾„
pretrained_model_name_or_path = 'internlm/internlm-chat-7b'
pretrained_model_name_or_path = './internlm2-finance-7b'
ä¿®æ”¹è®­ç»ƒæ•°æ®é›†ä¸ºæœ¬åœ°è·¯å¾„
data_path = 'timdettmers/openassistant-guanaco'
data_path = './data'
å¼€å§‹å¾®è°ƒ
xtuner train /root/finance/config2/internlm2_chat_7b_qlora_oasst1_e3_copy.py
PTH æ¨¡å‹è½¬æ¢ä¸º HuggingFace æ¨¡å‹
xtuner convert pth_to_hf ./internlm2_chat_7b_qlora_oasst1_e3_copy.py
./work_dirs/internlm2_chat_7b_qlora_oasst1_e3_copy/epoch_3.pth
./hf
HuggingFace æ¨¡å‹åˆå¹¶åˆ°å¤§è¯­è¨€æ¨¡å‹
export MKL_SERVICE_FORCE_INTEL=1
export MKL_THREADING_LAYER='GNU'
åŸå§‹æ¨¡å‹å‚æ•°å­˜æ”¾çš„ä½ç½®
export NAME_OR_PATH_TO_LLM=/root/finance/model/Shanghai_AI_Laboratory/internlm2-finance-7b

Hugging Faceæ ¼å¼å‚æ•°å­˜æ”¾çš„ä½ç½®
export NAME_OR_PATH_TO_ADAPTER=/root/finance/config/hf

æœ€ç»ˆMergeåçš„å‚æ•°å­˜æ”¾çš„ä½ç½®
mkdir /root/finance/config/work_dirs/hf_merge
export SAVE_PATH=/root/finance/config/work_dirs/hf_merge

æ‰§è¡Œå‚æ•°Merge
xtuner convert merge
$NAME_OR_PATH_TO_LLM
$NAME_OR_PATH_TO_ADAPTER
$SAVE_PATH
--max-shard-size 2GB
Demo
streamlit run web_demo.py --server.address=0.0.0.0 --server.port 7860
OpenXLabåº”ç”¨éƒ¨ç½²
ä»…éœ€è¦ Fork æœ¬ä»“åº“ï¼Œç„¶ååœ¨ OpenXLab ä¸Šåˆ›å»ºä¸€ä¸ªæ–°çš„é¡¹ç›®ï¼Œå°† Fork çš„ä»“åº“ä¸æ–°å»ºçš„é¡¹ç›®å…³è”ï¼Œå³å¯åœ¨ OpenXLab ä¸Šéƒ¨ç½² AMchatã€‚

Demo

AMchat ä¸ InternLM2-Finance-7B åœ¨ç§¯åˆ†é—®é¢˜ä¸Šå¯¹äºåŒä¸€é—®é¢˜çš„è§£ç­”ã€‚ AMchat å›ç­”æ­£ç¡®ï¼ŒInternLM2-Finance-7B å›ç­”é”™è¯¯ã€‚
Demo Demo

LMDeployé‡åŒ–
é¦–å…ˆå®‰è£…LMDeploy
pip install -U lmdeploy
ç„¶åè½¬æ¢æ¨¡å‹ä¸ºturbomindæ ¼å¼
--dst-path: å¯ä»¥æŒ‡å®šè½¬æ¢åçš„æ¨¡å‹å­˜å‚¨ä½ç½®ã€‚

lmdeploy convert internlm2-chat-7b è¦è½¬åŒ–çš„æ¨¡å‹åœ°å€ --dst-path è½¬æ¢åçš„æ¨¡å‹åœ°å€
LMDeploy Chat å¯¹è¯
lmdeploy chat turbomind è½¬æ¢åçš„turbomindæ¨¡å‹åœ°å€
OpenCompassè¯„æµ‹
å®‰è£… OpenCompass
git clone https://github.com/open-compass/opencompass
cd opencompass
pip install -e .
ä¸‹è½½è§£å‹æ•°æ®é›†
cp /share/temp/datasets/OpenCompassData-core-20231110.zip /root/opencompass/
unzip OpenCompassData-core-20231110.zip
è¯„æµ‹å¯åŠ¨ï¼
python run.py
--datasets finance_gen
--hf-path æ¨¡å‹åœ°å€
--tokenizer-path tokenizeråœ°å€
--tokenizer-kwargs padding_side='left' truncation='left' trust_remote_code=True
--model-kwargs device_map='auto' trust_remote_code=True
--max-seq-len 2048
--max-out-len 16
--batch-size 2
--num-gpus 1
--debug
LMDeploy & OpenCompassé‡åŒ–ä»¥åŠé‡åŒ–è¯„æµ‹
W4 é‡åŒ–è¯„æµ‹
KV Cache é‡åŒ–è¯„æµ‹
ç»“æœæ–‡ä»¶ä¸è¯„æµ‹æ•°æ®é›†å¯åœ¨åŒç›®å½•æ–‡ä»¶resultsä¸­è·å–
